import pandas as pd
import numpy as np
import tensorflow as tf
from keras.layers.noise import GaussianDropout
from keras.layers.noise import GaussianNoise
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.layers.normalization import BatchNormalization
from keras.layers.advanced_activations import PReLU, ThresholdedReLU, LeakyReLU, ELU
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.utils.np_utils import to_categorical
from sklearn.metrics import r2_score
import keras.backend as K
from keras import optimizers
from keras import  regularizers
from keras.constraints import maxnorm
import matplotlib.pyplot as plt

path = '/Users/charlie/Desktop/TrendMicro/'
tr = pd.read_csv(path +'tr.csv')
te = pd.read_csv(path +'te.csv')

features =['CustomerID_unique_count', 'ProductID_unique_count',
       'ProductID_V0374c4', 'ProductID_V055649', 'ProductID_V05b409',
       'ProductID_V0cdb7a', 'ProductID_V20f8a5', 'ProductID_V218578',
       'ProductID_V262880', 'ProductID_V26a5d0', 'ProductID_V3c2be6',
       'ProductID_V3ea8c3', 'ProductID_V533133', 'ProductID_V634e6b',
       'ProductID_V75f310', 'ProductID_V7acab3', 'ProductID_V8452da',
       'ProductID_V8541a0', 'ProductID_V885fab', 'ProductID_V8b7f69',
       'ProductID_Va310bb', 'ProductID_Vaaa9c8', 'ProductID_Vb93794',
       'ProductID_Vc105a0', 'ProductID_Vc76d58', 'ProductID_Vcc3a6a',
       'ProductID_Vd465fc', 'ProductID_Vdd8d4a', 'ProductID_Ve47f04',
       'ProductID_Vfec24f', 'f_count', 'week_V9', 'week_V10', 'week_V11',
       'week_V12', 'week_V13', 'week_V14', 'week_V15', 'week_V16',
       'week_V17', 'week_V18', 'week_V19', 'week_V20', 'week_V21',
       'week_V22', 'week_unique_count', 'month_unique_count', 'time_group',
           'user_behavior_group_v3_count_V0',
       'user_behavior_group_v3_count_V1',
       'user_behavior_group_v3_count_V2',
       'user_behavior_group_v3_count_V3', 'weekday_unique_count',
       'hour_unique_count',
        'mean_hour_count', 'max_hour_count',
       'min_hour_count', 'median_hour_count', 'mean_weekday_count',
       'max_weekday_count', 'min_weekday_count', 'median_weekday_count',
       'mean_week_count', 'max_week_count', 'min_week_count',
       'median_week_count', 'mean_month_count', 'max_month_count',
       'min_month_count', 'median_month_count',
           'std_month_count',
       'std_week_count', 'std_weekday_count', 'std_hour_count',
           'std_ProductID_count', 'mean_ProductID_count',
       'max_ProductID_count', 'min_ProductID_count',
       'median_ProductID_count', 'std_CustomerID_count',
       'mean_CustomerID_count', 'max_CustomerID_count',
       'min_CustomerID_count', 'median_CustomerID_count',
           'mean_FileID_QTS', 'max_FileID_QTS', 'min_FileID_QTS',
       'median_FileID_QTS', 'std_QueryTS_count',
           'mean_File_Customer_Product_diff', 'max_File_Customer_Product_diff',
       'min_File_Customer_Product_diff',
       'median_File_Customer_Product_diff',
       'std_File_Customer_Product_diff',
          'mean_FileID_diff',
       'max_FileID_diff', 'min_FileID_diff', 'median_FileID_diff',
       'std_FileID_diff',
'hour_V0', 'hour_V1', 'hour_V2', 'hour_V3', 'hour_V4', 'hour_V5',
       'hour_V6', 'hour_V7', 'hour_V8', 'hour_V9', 'hour_V10', 'hour_V11',
       'hour_V12', 'hour_V13', 'hour_V14', 'hour_V15', 'hour_V16',
       'hour_V17', 'hour_V18', 'hour_V19', 'hour_V20', 'hour_V21',
       'hour_V22', 'hour_V23',
           'weekday_V0', 'weekday_V1', 'weekday_V2', 'weekday_V3',
       'weekday_V4', 'weekday_V5', 'weekday_V6',
           'mean_Customer_diff', 'max_Customer_diff',
       'min_Customer_diff', 'median_Customer_diff', 'std_Customer_diff',
       'mean_Product_diff', 'max_Product_diff', 'min_Product_diff',
       'median_Product_diff', 'std_Product_diff',
           'mean_FileID_CustomerID_ProductID_hour_count',
       'max_FileID_CustomerID_ProductID_hour_count',
       'min_FileID_CustomerID_ProductID_hour_count',
       'median_FileID_CustomerID_ProductID_hour_count',
       'std_FileID_CustomerID_ProductID_hour_count',
           'mean_FileID_CustomerID_ProductID_weekday_count',
       'max_FileID_CustomerID_ProductID_weekday_count',
       'min_FileID_CustomerID_ProductID_weekday_count',
       'median_FileID_CustomerID_ProductID_weekday_count',
       'std_FileID_CustomerID_ProductID_weekday_count',
 'customer_ratio_mean',
 'customer_ratio_std',
 'customer_ratio_range',
 'customer_ratio_0',
 'customer_ratio_10',
 'customer_ratio_20',
 'customer_ratio_30',
 'customer_ratio_40',
 'customer_ratio_50',
 'customer_ratio_60',
 'customer_ratio_70',
 'customer_ratio_80',
 'customer_ratio_90',
 'customer_ratio_100',
 'prod_ratio_mean',
 'prod_ratio_std',
 'prod_ratio_range',
 'prod_ratio_0',
 'prod_ratio_10',
 'prod_ratio_20',
 'prod_ratio_30',
 'prod_ratio_40',
 'prod_ratio_50',
 'prod_ratio_60',
 'prod_ratio_70',
 'prod_ratio_80',
 'prod_ratio_90',
 'prod_ratio_100',
           'cust_prod_ratio_mean', 'cust_prod_ratio_std',
       'cust_prod_ratio_range', 'cust_prod_ratio_0', 'cust_prod_ratio_10',
       'cust_prod_ratio_20', 'cust_prod_ratio_30', 'cust_prod_ratio_40',
       'cust_prod_ratio_50', 'cust_prod_ratio_60', 'cust_prod_ratio_70',
       'cust_prod_ratio_80', 'cust_prod_ratio_90', 'cust_prod_ratio_100',
           'hour_ratio_mean', 'hour_ratio_std', 'hour_ratio_range',
       'hour_ratio_0', 'hour_ratio_10', 'hour_ratio_20', 'hour_ratio_30',
       'hour_ratio_40', 'hour_ratio_50', 'hour_ratio_60', 'hour_ratio_70',
       'hourratio_80', 'hour_ratio_90', 'hour_ratio_100',
           'weekday_ratio_mean', 'weekdayratio_std', 'weekday_ratio_range',
       'weekday_ratio_0', 'weekday_ratio_10', 'weekday_ratio_20',
       'weekday_ratio_30', 'weekday_ratio_40', 'weekday_ratio_50',
       'weekday_ratio_60', 'weekday_ratio_70', 'weekday_ratio_80',
       'weekday_ratio_90', 'weekday_ratio_100', 'week_ratio_mean',
       'week_ratio_std', 'week_ratio_range', 'week_ratio_0',
       'week_ratio_10', 'week_ratio_20', 'week_ratio_30', 'week_ratio_40',
       'week_ratio_50', 'week_ratio_60', 'week_ratio_70', 'week_ratio_80',
       'week_ratio_90', 'week_ratio_100',
           'count_ratio_0_10',
       'count_ratio_10_20', 'count_ratio_20_30', 'count_ratio_30_40',
       'count_ratio_40_50', 'count_ratio_50_60', 'count_ratio_60_70',
       'count_ratio_70_80', 'count_ratio_80_90', 'count_ratio_90_100',
           'prod_ratio_0_10', 'prod_ratio_10_20',
       'prod_ratio_20_30', 'prod_ratio_30_40', 'prod_ratio_40_50',
       'prod_ratio_50_60', 'prod_ratio_60_70', 'prod_ratio_70_80',
       'prod_ratio_80_90', 'prod_ratio_90_100', 'hour_ratio_0_10',
       'hour_ratio_10_20', 'hour_ratio_20_30', 'hour_ratio_30_40',
       'hour_ratio_40_50', 'hour_ratio_50_60', 'hour_ratio_60_70',
       'hour_ratio_70_80', 'hour_ratio_80_90', 'hour_ratio_90_100',
           'mean_FileID_hour_diff',
       'max_FileID_hour_diff', 'min_FileID_hour_diff',
       'median_FileID_hour_diff', 'std_FileID_hour_diff'
          ]

Y_train = tr.bug.values
X_train = tr[features].values
X_test = te[features].values

adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)

def r2_keras(y_true, y_pred):
    SS_res = K.sum(K.square(y_true - y_pred))
    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))
    return (1 - SS_res / (SS_tot + K.epsilon()))

def root_mean_squared_error(y_true, y_pred):
    return(K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)))

def extract_features(model, X, layer):
    get_layer_output = K.function([model.layers[0].input, K.learning_phase()],
                                      [model.layers[layer].output])
    layer_output = get_layer_output([X, 1])[0]

    return(np.asarray(layer_output))

act_fun = 'relu'


def nn_model():
    model = Sequential()

    model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1]))
    model.add(BatchNormalization())
    model.add(Activation(act_fun))

    model.add(Dense(int(1.3 * X_train.shape[1]), kernel_constraint=maxnorm(3)))
    model.add(BatchNormalization())
    model.add(Activation(act_fun))



    model.add(Dense(X_train.shape[1] // 16, kernel_constraint=maxnorm(3)))
    model.add(BatchNormalization())
    model.add(Activation(act_fun))
    model.add(Dropout(0.05))

    model.add(Dense(X_train.shape[1] // 32, kernel_constraint=maxnorm(3)))
    model.add(BatchNormalization())
    model.add(Activation(act_fun))

    model.add(Dense(X_train.shape[1] // 64, kernel_constraint=maxnorm(3)))
    model.add(BatchNormalization())
    model.add(Activation(act_fun))

    model.add(Dense(X_train.shape[1] // 32,  kernel_constraint=maxnorm(3)))
    model.add(Activation(act_fun))


    model.add(Dense(X_train.shape[1] // 16, kernel_constraint=maxnorm(3)))
    model.add(BatchNormalization())
    model.add(Activation(act_fun))
    model.add(Dropout(0.05))


    model.add(Dense(int(1.3 * X_train.shape[1]), kernel_constraint=maxnorm(3)))
    model.add(BatchNormalization())
    model.add(Activation(act_fun))


    model.add(Dense(X_train.shape[1], activation='relu')) #activity_regularizer=regularizers.l1(0.01))
    model.compile(loss='mean_squared_error', optimizer=adam, metrics=[r2_keras, root_mean_squared_error])
    return(model)


model = nn_model()
print(model.summary())

history = model.fit(X_train, X_train, nb_epoch = 750, batch_size=200, verbose = 1, validation_split = 0.2, shuffle=True)

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['r2_keras'])
plt.plot(history.history['val_r2_keras'])
plt.title('model r2')
plt.ylabel('r2')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()

X_tr = extract_features(model, X_train, 13)
X_te = extract_features(model, X_test, 13)

X_tr = pd.DataFrame(X_tr)
#Y_tr = pd.DataFrame(Y_train)
X_te = pd.DataFrame(X_te)
#train = pd.concat([X_tr, Y_tr],axis=1)

X_tr.columns = ['AE_'+ str(i) for i in range(0,4)]
X_te.columns = ['AE_'+ str(i) for i in range(0,4)]

tr = pd.concat([tr, X_tr],axis=1)
te = pd.concat([te, X_te],axis=1)

print(len(X_tr))
print(len(X_te))

tr.to_csv(path+'train_AE.csv',index=False)
te.to_csv(path+'test_AE.csv',index=False)

